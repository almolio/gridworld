{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42  # TODO: set seed to allow for reproducibility of results\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# initialize environment\n",
    "from envs.environment_t import Environment \n",
    "\n",
    "from utils.helper_fcts import display_state\n",
    "\n",
    "data_dir = os.path.join(os.path.abspath(''), 'data')\n",
    "variant = 0  # TODO: specify problem variant (0 for base variant, 1 for first extension, 2 for second extension)\n",
    "env = Environment(variant, data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.display import display\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from torch import Tensor, nn\n",
    "from torch.optim import Adam, Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import IterableDataset\n",
    "import random\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from itertools import compress, chain\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import time \n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.5\n",
    "EPS_START = 0.999\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1e10\n",
    "TAU = 0.005\n",
    "LR = 1e-6\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    '''Trying the simple network'''\n",
    "    \n",
    "    def __init__(self, obs_size:int, n_actions: int, hidden_size: int=256):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_size, hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, n_actions),\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',('state','action','next_state','reward'))\n",
    "# TODO: Here is probabl will give an issue regarding which information we can have \n",
    "# from the environment \n",
    "\n",
    "class ReplayMemory(object): \n",
    "    def __init__(self, capacity) -> None:\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "        \n",
    "    def push(self, *args):\n",
    "        '''Append to the buffer'''\n",
    "        self.memory.append(Transition(*args))\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.path.abspath(\"\"), \"data\")\n",
    "env = Environment(0, data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = 5\n",
    "# Get the number of state observations\n",
    "mode = \"training\"\n",
    "state = env.reset(mode)\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "# Copy the main network to target network \n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = Adam(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(200)\n",
    "\n",
    "steps_done = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils Scripts ( Visualization and WnB )\n",
    "TODO: Move this into a util scripts for us to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST STATE\n",
    "# state = np.zeros([5,5])\n",
    "# state[0][2] = 3 # target\n",
    "# state[3][4] = 1 # agent\n",
    "# state[4][0] = 2 # item\n",
    "# state[2][3] = 2 # item\n",
    "# display_state(state=state, episode=1)\n",
    "\n",
    "display_state(state=env.get_state(), episode=1)\n",
    "# print(env.get_state())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight and biases setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenoitauclair30\u001b[0m (\u001b[33mdrl_tum2023\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/benoit/Documents/00_git/drl_grid_world/wandb/run-20230508_223420-hmv871zl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/drl_tum2023/Warehouse%20Gridworld/runs/hmv871zl' target=\"_blank\">misunderstood-universe-2</a></strong> to <a href='https://wandb.ai/drl_tum2023/Warehouse%20Gridworld' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/drl_tum2023/Warehouse%20Gridworld' target=\"_blank\">https://wandb.ai/drl_tum2023/Warehouse%20Gridworld</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/drl_tum2023/Warehouse%20Gridworld/runs/hmv871zl' target=\"_blank\">https://wandb.ai/drl_tum2023/Warehouse%20Gridworld/runs/hmv871zl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/drl_tum2023/Warehouse%20Gridworld/runs/hmv871zl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4e8e71bb90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Warehouse Gridworld\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"architecture\": \"DQN\",\n",
    "    \"learning_rate\": LR,\n",
    "    \"batchsize\": BATCH_SIZE,\n",
    "    \"gamma\" : GAMMA,\n",
    "    \"tau\" : TAU,\n",
    "    \"epsilon_start\" : EPS_START,\n",
    "    \"epsilon_end\": EPS_END,\n",
    "    \"epsilon_decay\" : EPS_DECAY\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Create a new class agent and put select_action in: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state):\n",
    "    '''Action selection based on decay greedy\n",
    "    TODO: we could also implement based on epsilon-greedy\n",
    "    '''\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    # print(f\"{steps_done} step: threshol is {eps_threshold}\")\n",
    "    \n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            action_chosen = policy_net(state).max(1)[1].view(1, 1)\n",
    "            return action_chosen\n",
    "    else:\n",
    "        action_space = range(5)\n",
    "        action_chosen = torch.tensor([random.sample(action_space,1)], device=device, dtype=torch.long)\n",
    "        return action_chosen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning loop   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(): \n",
    "    if len(memory) < BATCH_SIZE: \n",
    "        return \n",
    "    \n",
    "    # turn the transition to batch \n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # print(f\" Sample Transition {transitions[15]}\")\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    # print(f\" Batch for training {batch.action}\")\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "    # Compute Q(s_t, a)\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    # --> get the output of the net using the state, where an action was taken\n",
    "    # \n",
    "    \n",
    "    # Comput Vs for all nextstate \n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad(): \n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
    "        \n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    \n",
    "    # Compute Huber Loss \n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    \n",
    "    # Optimize the model \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Inplace gradient clipping \n",
    "    # torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Start, running on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/5000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 / 5000, validation reward: -106.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                         | 12/5000 [00:10<59:56,  1.39it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m memory\u001b[38;5;241m.\u001b[39mpush(state, action, next_state, reward)\n\u001b[1;32m     49\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m---> 51\u001b[0m optimize_model()\n\u001b[1;32m     53\u001b[0m target_net_state_dict \u001b[38;5;241m=\u001b[39m target_net\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m     54\u001b[0m policy_net_state_dict \u001b[38;5;241m=\u001b[39m policy_net\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m, in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(f\" Batch for training {batch.action}\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m non_final_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m s: s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                                       batch\u001b[38;5;241m.\u001b[39mnext_state)), device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[0;32m---> 12\u001b[0m non_final_next_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mnext_state\n\u001b[1;32m     13\u001b[0m                                             \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m])\n\u001b[1;32m     14\u001b[0m state_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(batch\u001b[38;5;241m.\u001b[39mstate)\n\u001b[1;32m     15\u001b[0m action_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(batch\u001b[38;5;241m.\u001b[39maction)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 5000\n",
    "else: \n",
    "    num_episodes = 50\n",
    "    \n",
    "cummulative_reward = []\n",
    "from tqdm import tqdm\n",
    "# display_state(state=env.get_state(), episode=1)\n",
    "\n",
    "print(f'Training Start, running on {device}')\n",
    "\n",
    "pbar = tqdm(total=num_episodes)\n",
    "for i_expisode in range(num_episodes):\n",
    "    # Run Validation Reward\n",
    "    if i_expisode % 100 == 0 : \n",
    "        val_rew = 0 \n",
    "        state = env.reset(\"training\")\n",
    "        state = torch.tensor(state, dtype=torch.float32, device = device).unsqueeze(0)\n",
    "        for j in range(200):  # loop over 200 steps per episode\n",
    "            act = select_action(state)  # TODO: get action for the obs from your trained policy\n",
    "            rew, next_obs, _ = env.step(act)  # take one step in the environment\n",
    "            val_rew += rew  # track rewards\n",
    "            obs = next_obs  # continue from the new obs\n",
    "        wandb.log({\n",
    "            \"val_reward\": val_rew\n",
    "        })    \n",
    "        pbar.write(f'Episode {i_expisode} / {num_episodes}, validation reward: {val_rew}')\n",
    "\n",
    "    state = env.reset(mode)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device = device).unsqueeze(0)\n",
    "    \n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        reward, observation, done = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        if done: \n",
    "            next_state = None\n",
    "        else: \n",
    "            # visualization\n",
    "            # clear_output(wait=True)\n",
    "            # display_state(state=env.get_state(), episode=i_expisode)\n",
    "            # time.sleep(0.4)\n",
    "            \n",
    "            next_state = torch.tensor(observation, dtype=torch.float32,device=device).unsqueeze(0)\n",
    "    \n",
    "        # store in memory \n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "        optimize_model()\n",
    "        \n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        \n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU \\\n",
    "                + target_net_state_dict[key]*(1-TAU)\n",
    "                \n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "        \n",
    "        if done: \n",
    "            cummulative_reward.append(reward)\n",
    "            break\n",
    "    pbar.update(1)    \n",
    "\n",
    "print('complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the game with the final state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset(\"training\")\n",
    "state = torch.tensor(state, dtype=torch.float32, device = device).unsqueeze(0)\n",
    "\n",
    "for j in range(200):  # loop over 200 steps per episode\n",
    "  \n",
    "    act = select_action(state)  # TODO: get action for the obs from your trained policy\n",
    "    rew, next_obs, _ = env.step(act)  # take one step in the environment\n",
    "    # visualization\n",
    "    clear_output(wait=True)\n",
    "    display_state(state=env.get_state(), episode=i_expisode)\n",
    "    time.sleep(0.2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
